---
# Sovereign Soil Playbook
# Provisions Hetzner bare metal servers to run Enclii's Sovereign Cloud
#
# Target: Ubuntu 22.04/24.04
# Distribution: k3s (Lightweight Kubernetes)
# Ingress: Traefik (default with k3s)
#
# Usage:
#   ansible-playbook -i inventory.ini playbook.yml

- name: Provision Enclii Sovereign Cloud on Hetzner Bare Metal
  hosts: enclii_masters
  become: true
  gather_facts: true

  tasks:
    # ========================================================================
    # PHASE 1: System Hardening
    # ========================================================================

    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
      tags: [hardening]

    - name: Upgrade all packages to latest version
      apt:
        upgrade: dist
      tags: [hardening]

    - name: Install system hardening packages
      apt:
        name:
          - ufw
          - fail2ban
          - unattended-upgrades
          - apt-listchanges
        state: present
      tags: [hardening]

    - name: Configure UFW - Allow SSH
      ufw:
        rule: allow
        port: '22'
        proto: tcp
        comment: 'SSH'
      tags: [hardening]

    - name: Configure UFW - Allow HTTP
      ufw:
        rule: allow
        port: '80'
        proto: tcp
        comment: 'HTTP'
      tags: [hardening]

    - name: Configure UFW - Allow HTTPS
      ufw:
        rule: allow
        port: '443'
        proto: tcp
        comment: 'HTTPS'
      tags: [hardening]

    - name: Configure UFW - Allow Kubernetes API
      ufw:
        rule: allow
        port: '6443'
        proto: tcp
        comment: 'Kubernetes API Server'
      tags: [hardening]

    - name: Enable UFW
      ufw:
        state: enabled
        policy: deny
      tags: [hardening]

    - name: Ensure fail2ban is running
      systemd:
        name: fail2ban
        state: started
        enabled: yes
      tags: [hardening]

    # ========================================================================
    # PHASE 2: Container Runtime - Install k3s
    # ========================================================================

    - name: Check if k3s is already installed
      stat:
        path: /usr/local/bin/k3s
      register: k3s_binary
      tags: [k3s]

    - name: Download k3s installation script
      get_url:
        url: https://get.k3s.io
        dest: /tmp/k3s-install.sh
        mode: '0755'
      when: not k3s_binary.stat.exists
      tags: [k3s]

    - name: Install k3s in server mode (with default Traefik)
      shell: |
        INSTALL_K3S_VERSION={{ k3s_version | default('v1.28.5+k3s1') }} \
        sh /tmp/k3s-install.sh server \
          --write-kubeconfig-mode 644 \
          --disable servicelb
      when: not k3s_binary.stat.exists
      tags: [k3s]
      # Note: We keep Traefik enabled (default behavior)
      # servicelb is disabled as we'll use Cloudflare Tunnel instead

    - name: Wait for k3s to be ready
      wait_for:
        path: /etc/rancher/k3s/k3s.yaml
        timeout: 300
      tags: [k3s]

    - name: Create .kube directory for root user
      file:
        path: /root/.kube
        state: directory
        mode: '0755'
      tags: [k3s]

    - name: Copy k3s kubeconfig to standard location
      copy:
        src: /etc/rancher/k3s/k3s.yaml
        dest: /root/.kube/config
        remote_src: yes
        mode: '0600'
      tags: [k3s]

    - name: Verify k3s cluster is running
      command: kubectl get nodes
      register: k3s_nodes
      changed_when: false
      tags: [k3s]

    - name: Display k3s cluster status
      debug:
        msg: "{{ k3s_nodes.stdout_lines }}"
      tags: [k3s]

    # ========================================================================
    # PHASE 3: Dependencies - Install Helm
    # ========================================================================

    - name: Check if Helm is already installed
      stat:
        path: /usr/local/bin/helm
      register: helm_binary
      tags: [helm]

    - name: Download Helm installation script
      get_url:
        url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
        dest: /tmp/get-helm-3.sh
        mode: '0755'
      when: not helm_binary.stat.exists
      tags: [helm]

    - name: Install Helm
      command: /tmp/get-helm-3.sh
      when: not helm_binary.stat.exists
      tags: [helm]

    - name: Verify Helm installation
      command: helm version --short
      register: helm_version
      changed_when: false
      tags: [helm]

    - name: Display Helm version
      debug:
        msg: "{{ helm_version.stdout }}"
      tags: [helm]

    # ========================================================================
    # PHASE 4: Certificates - Install cert-manager
    # ========================================================================

    - name: Add Jetstack Helm repository
      command: helm repo add jetstack https://charts.jetstack.io
      register: helm_repo_add
      changed_when: "'already exists' not in helm_repo_add.stderr"
      tags: [cert-manager]

    - name: Update Helm repositories
      command: helm repo update
      tags: [cert-manager]

    - name: Create cert-manager namespace
      command: kubectl create namespace cert-manager
      register: cert_manager_ns
      failed_when:
        - cert_manager_ns.rc != 0
        - "'AlreadyExists' not in cert_manager_ns.stderr"
      changed_when: cert_manager_ns.rc == 0
      tags: [cert-manager]

    - name: Install cert-manager CRDs
      command: >
        kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.crds.yaml
      tags: [cert-manager]

    - name: Install cert-manager via Helm
      command: >
        helm upgrade --install cert-manager jetstack/cert-manager
        --namespace cert-manager
        --version v1.13.3
        --set installCRDs=true
        --wait
      tags: [cert-manager]

    - name: Wait for cert-manager to be ready
      command: kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=cert-manager -n cert-manager --timeout=300s
      tags: [cert-manager]

    - name: Verify cert-manager installation
      command: kubectl get pods -n cert-manager
      register: cert_manager_pods
      changed_when: false
      tags: [cert-manager]

    - name: Display cert-manager pods
      debug:
        msg: "{{ cert_manager_pods.stdout_lines }}"
      tags: [cert-manager]

    # ========================================================================
    # PHASE 5: Namespaces - Create janua-prod
    # ========================================================================

    - name: Create janua-prod namespace
      command: kubectl create namespace janua-prod
      register: janua_ns
      failed_when:
        - janua_ns.rc != 0
        - "'AlreadyExists' not in janua_ns.stderr"
      changed_when: janua_ns.rc == 0
      tags: [namespaces]

    - name: Verify janua-prod namespace
      command: kubectl get namespace janua-prod
      register: janua_namespace
      changed_when: false
      tags: [namespaces]

    - name: Display namespace status
      debug:
        msg: "Namespace janua-prod is ready"
      tags: [namespaces]

    # ========================================================================
    # PHASE 6: Final Status Report
    # ========================================================================

    - name: Get all namespaces
      command: kubectl get namespaces
      register: all_namespaces
      changed_when: false
      tags: [status]

    - name: Display final cluster status
      debug:
        msg:
          - "========================================="
          - "Sovereign Cloud Provisioning Complete!"
          - "========================================="
          - ""
          - "Cluster Namespaces:"
          - "{{ all_namespaces.stdout_lines }}"
          - ""
          - "Next Steps:"
          - "1. Deploy Janua: kubectl apply -f k8s/janua.yaml"
          - "2. Configure DNS for janua.dev to point to your server IP"
          - "3. Set up LetsEncrypt ClusterIssuer for TLS certificates"
      tags: [status]
